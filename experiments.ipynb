{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71b0878a-4047-42af-b5df-115766153692",
   "metadata": {},
   "source": [
    "# Experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7cd254-688c-4301-97ec-b2a87a1bf055",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abc68fe-7314-4ee4-aa5c-a6602ea26ad2",
   "metadata": {},
   "source": [
    "* Prerequisites\n",
    "    * `pip3 install torch == 1.2.0`\n",
    "    * `pip3 install gym == 0.23.1`\n",
    "    * `pip3 install mujoco == 2.2.1`\n",
    "* For lunar lander    \n",
    "    * `conda install swig`\n",
    "    * `pip3 install box2d-py`\n",
    "* if there's a`mujoco_py does not exist` error, on the `gym` and/or `d4rl` package, import `mujoco as mujoco_py`\n",
    "\n",
    "* Pybullet datasets reference\n",
    "    * https://github.com/takuseno/d4rl-pybullet\n",
    "    * https://github.com/Farama-Foundation/D4RL/tree/f2a05c0d66722499bf8031b094d9af3aea7c372b\n",
    "    \n",
    "* PLAS algorithm\n",
    "    * https://github.com/Wenxuan-Zhou/PLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa69fdc-da39-463d-9022-76bbc0ffc974",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f290ee5d-e15b-4eba-911d-b235134ddd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Mujoco-based envs failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'mujoco_py'\n",
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'flow'\n",
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'carla'\n",
      "Warning: GymBullet failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'mujoco_py'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Based on https://github.com/sfujim/BCQ\n",
    "\"\"\"\n",
    "import argparse\n",
    "import gym\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import utils\n",
    "import algos\n",
    "from logger import logger, setup_logger\n",
    "import d4rl\n",
    "import torch\n",
    "import time\n",
    "from eval_functions import eval_critic\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24634dd-04a8-47f5-bd1f-7aa9efb4185c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prince/anaconda3/envs/plas/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# force cpu\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566545ff-eccc-4121-b3ff-b4bbba43770d",
   "metadata": {},
   "source": [
    "## Gym Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ebbfd4e-71d9-40ac-aca7-e928a2372ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValuesView(├──CartPole: [ v0, v1 ]\n",
      "├──MountainCar: [ v0 ]\n",
      "├──MountainCarContinuous: [ v0 ]\n",
      "├──Pendulum: [ v1 ]\n",
      "├──Acrobot: [ v1 ]\n",
      "├──LunarLander: [ v2 ]\n",
      "├──LunarLanderContinuous: [ v2 ]\n",
      "├──BipedalWalker: [ v3 ]\n",
      "├──BipedalWalkerHardcore: [ v3 ]\n",
      "├──CarRacing: [ v1 ]\n",
      "├──Blackjack: [ v1 ]\n",
      "├──FrozenLake: [ v1 ]\n",
      "├──FrozenLake8x8: [ v1 ]\n",
      "├──CliffWalking: [ v0 ]\n",
      "├──Taxi: [ v3 ]\n",
      "├──Reacher: [ v2 ]\n",
      "├──Pusher: [ v2 ]\n",
      "├──InvertedPendulum: [ v2 ]\n",
      "├──InvertedDoublePendulum: [ v2 ]\n",
      "├──HalfCheetah: [ v2, v3 ]\n",
      "├──Hopper: [ v2, v3 ]\n",
      "├──Swimmer: [ v2, v3 ]\n",
      "├──Walker2d: [ v2, v3 ]\n",
      "├──Ant: [ v2, v3 ]\n",
      "├──Humanoid: [ v2, v3 ]\n",
      "├──HumanoidStandup: [ v2 ]\n",
      "├──kitchen_relax: [ v1 ]\n",
      "├──kitchen-complete: [ v0 ]\n",
      "├──kitchen-partial: [ v0 ]\n",
      "├──kitchen-mixed: [ v0 ]\n",
      "├──HumanoidDeepMimicBackflipBulletEnv: [ v1 ]\n",
      "├──HumanoidDeepMimicWalkBulletEnv: [ v1 ]\n",
      "├──CartPoleBulletEnv: [ v1 ]\n",
      "├──CartPoleContinuousBulletEnv: [ v0 ]\n",
      "├──MinitaurBulletEnv: [ v0 ]\n",
      "├──MinitaurBulletDuckEnv: [ v0 ]\n",
      "├──MinitaurExtendedEnv: [ v0 ]\n",
      "├──MinitaurReactiveEnv: [ v0 ]\n",
      "├──MinitaurBallGymEnv: [ v0 ]\n",
      "├──MinitaurTrottingEnv: [ v0 ]\n",
      "├──MinitaurStandGymEnv: [ v0 ]\n",
      "├──MinitaurAlternatingLegsEnv: [ v0 ]\n",
      "├──MinitaurFourLegStandEnv: [ v0 ]\n",
      "├──RacecarBulletEnv: [ v0 ]\n",
      "├──RacecarZedBulletEnv: [ v0 ]\n",
      "├──KukaBulletEnv: [ v0 ]\n",
      "├──KukaCamBulletEnv: [ v0 ]\n",
      "├──KukaDiverseObjectGrasping: [ v0 ]\n",
      "├──InvertedPendulumBulletEnv: [ v0 ]\n",
      "├──InvertedDoublePendulumBulletEnv: [ v0 ]\n",
      "├──InvertedPendulumSwingupBulletEnv: [ v0 ]\n",
      "├──ReacherBulletEnv: [ v0 ]\n",
      "├──PusherBulletEnv: [ v0 ]\n",
      "├──ThrowerBulletEnv: [ v0 ]\n",
      "├──Walker2DBulletEnv: [ v0 ]\n",
      "├──HalfCheetahBulletEnv: [ v0 ]\n",
      "├──AntBulletEnv: [ v0 ]\n",
      "├──HopperBulletEnv: [ v0 ]\n",
      "├──HumanoidBulletEnv: [ v0 ]\n",
      "├──HumanoidFlagrunBulletEnv: [ v0 ]\n",
      "├──HumanoidFlagrunHarderBulletEnv: [ v0 ]\n",
      "├──bullet-hopper: [ v0 ]\n",
      "├──bullet-hopper-random: [ v0 ]\n",
      "├──bullet-hopper-medium: [ v0 ]\n",
      "├──bullet-hopper-expert: [ v0 ]\n",
      "├──bullet-hopper-medium-expert: [ v0 ]\n",
      "├──bullet-hopper-medium-replay: [ v0 ]\n",
      "├──bullet-halfcheetah: [ v0 ]\n",
      "├──bullet-halfcheetah-random: [ v0 ]\n",
      "├──bullet-halfcheetah-medium: [ v0 ]\n",
      "├──bullet-halfcheetah-expert: [ v0 ]\n",
      "├──bullet-halfcheetah-medium-expert: [ v0 ]\n",
      "├──bullet-halfcheetah-medium-replay: [ v0 ]\n",
      "├──bullet-ant: [ v0 ]\n",
      "├──bullet-ant-random: [ v0 ]\n",
      "├──bullet-ant-medium: [ v0 ]\n",
      "├──bullet-ant-expert: [ v0 ]\n",
      "├──bullet-ant-medium-expert: [ v0 ]\n",
      "├──bullet-ant-medium-replay: [ v0 ]\n",
      "├──bullet-walker2d: [ v0 ]\n",
      "├──bullet-walker2d-random: [ v0 ]\n",
      "├──bullet-walker2d-medium: [ v0 ]\n",
      "├──bullet-walker2d-expert: [ v0 ]\n",
      "├──bullet-walker2d-medium-expert: [ v0 ]\n",
      "└──bullet-walker2d-medium-replay: [ v0 ]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(gym.envs.registry.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0867d-6f5b-44a6-9c51-b783ac5efe6d",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71432ac0-0201-4245-9af2-64c00e339cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tb\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "\n",
    "# # Additional parameters\n",
    "# parser.add_argument(\"--ExpID\", default=1, type=int)              # Experiment ID\n",
    "# parser.add_argument('--log_dir', default='./results/', type=str)    # Logging directory\n",
    "# parser.add_argument(\"--load_model\", default=None, type=str)         # Load model and optimizer parameters\n",
    "# parser.add_argument(\"--save_model\", default=True, type=bool)        # Save model and optimizer parameters\n",
    "# parser.add_argument(\"--save_freq\", default=1e5, type=int)           # How often it saves the model\n",
    "# #parser.add_argument(\"--env_name\", default=\"walker2d-medium-v0\")     # OpenAI gym environment name\n",
    "# parser.add_argument(\"--env_name\", default='bullet-walker2d-medium-v0')     # OpenAI gym environment name\n",
    "# parser.add_argument(\"--algo_name\", default=\"Latent\")                # Algorithm: Latent or LatentPerturbation.\n",
    "# parser.add_argument(\"--dataset\", default=None, type=str)            # path to dataset if not d4rl env\n",
    "# parser.add_argument(\"--seed\", default=0, type=int)                  # Sets Gym, PyTorch and Numpy seeds\n",
    "# parser.add_argument(\"--eval_freq\", default=1e3, type=int)           # How often (time steps) we evaluate\n",
    "# parser.add_argument(\"--max_timesteps\", default=5e5, type=int)       # Max time steps to run environment for\n",
    "# parser.add_argument('--vae_mode', default='train', type=str)\t\t# VAE mode: train or load from a specific version\n",
    "# parser.add_argument('--vae_lr', default=1e-4, type=float)\t\t    # vae training iterations\n",
    "# parser.add_argument('--vae_itr', default=500000, type=int)\t\t    # vae training iterations\n",
    "# parser.add_argument('--vae_hidden_size', default=750, type=int)\t\t# vae training iterations\n",
    "# parser.add_argument('--max_latent_action', default=2., type=float)  # max action of the latent policy\n",
    "# parser.add_argument('--phi', default=0., type=float)\t            # max perturbation\n",
    "# parser.add_argument('--batch_size', default=100, type=int)\t        # batch size\n",
    "# parser.add_argument('--actor_lr', default=1e-4, type=float)\t        # policy learning rate\n",
    "# parser.add_argument('--critic_lr', default=1e-3, type=float)\t    # policy learning rate\n",
    "# parser.add_argument('--tau', default=0.005, type=float)\t            # actor network size\n",
    "\n",
    "# # args = parser.parse_args()\n",
    "# args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc96cea9-65f0-40ac-9ba4-e0e744edeea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    }
   ],
   "source": [
    "%tb\n",
    "\n",
    "div = 1\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Additional parameters\n",
    "parser.add_argument(\"--ExpID\", default=1, type=int)              # Experiment ID\n",
    "parser.add_argument('--log_dir', default='./results/', type=str)    # Logging directory\n",
    "parser.add_argument(\"--load_model\", default=None, type=str)         # Load model and optimizer parameters\n",
    "parser.add_argument(\"--save_model\", default=True, type=bool)        # Save model and optimizer parameters\n",
    "parser.add_argument(\"--save_freq\", default=1e4//div, type=int)           # How often it saves the model\n",
    "parser.add_argument(\"--env_name\", default='bullet-walker2d-random-v0')     # OpenAI gym environment name\n",
    "# parser.add_argument(\"--env_name\", default='LunarLander-v2')     # OpenAI gym environment name\n",
    "parser.add_argument(\"--algo_name\", default=\"Latent\")                # Algorithm: Latent or LatentPerturbation.\n",
    "parser.add_argument(\"--dataset\", default=None, type=str)            # path to dataset if not d4rl env\n",
    "parser.add_argument(\"--seed\", default=0, type=int)                  # Sets Gym, PyTorch and Numpy seeds\n",
    "parser.add_argument(\"--eval_freq\", default=1e3//div, type=int)           # How often (time steps) we evaluate\n",
    "parser.add_argument(\"--max_timesteps\", default=5e5//div, type=int)       # Max time steps to run environment for\n",
    "parser.add_argument('--vae_mode', default='train', type=str)\t\t# VAE mode: train or load from a specific version\n",
    "parser.add_argument('--vae_lr', default=1e-4, type=float)\t\t    # vae training iterations\n",
    "parser.add_argument('--vae_itr', default=500000//div, type=int)\t\t    # vae training iterations\n",
    "parser.add_argument('--vae_hidden_size', default=750, type=int)\t\t# vae training iterations\n",
    "parser.add_argument('--max_latent_action', default=2., type=float)  # max action of the latent policy\n",
    "parser.add_argument('--phi', default=0., type=float)\t            # max perturbation\n",
    "parser.add_argument('--batch_size', default=100, type=int)\t        # batch size\n",
    "parser.add_argument('--actor_lr', default=1e-4, type=float)\t        # policy learning rate\n",
    "parser.add_argument('--critic_lr', default=1e-3, type=float)\t    # policy learning rate\n",
    "parser.add_argument('--tau', default=0.005, type=float)\t            # actor network size\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6e42f3-6843-4e5c-a2f0-7b1a6e308511",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079fc3df-4937-4acd-9e8e-252ed97697ab",
   "metadata": {},
   "source": [
    "### Folders, Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f945a8b2-8f1c-4a26-94ab-cd3be5ec10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete results\n",
    "# if os.path.isdir('./results'):\n",
    "#     shutil.rmtree('./results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181f2f47-eee9-4479-bb87-ca8bb8f6b4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/Exp0001_Latent_bullet-walker2d-random-v0-0\n",
      "2022-08-29 16:29:02.213850 PST | Variant:\n",
      "2022-08-29 16:29:02.214145 PST | {\n",
      "  \"ExpID\": 1,\n",
      "  \"log_dir\": \"./results/\",\n",
      "  \"load_model\": null,\n",
      "  \"save_model\": true,\n",
      "  \"save_freq\": 10000.0,\n",
      "  \"env_name\": \"bullet-walker2d-random-v0\",\n",
      "  \"algo_name\": \"Latent\",\n",
      "  \"dataset\": \"bullet-walker2d-random-v0\",\n",
      "  \"seed\": 0,\n",
      "  \"eval_freq\": 1000.0,\n",
      "  \"max_timesteps\": 500000.0,\n",
      "  \"vae_mode\": \"train\",\n",
      "  \"vae_lr\": 0.0001,\n",
      "  \"vae_itr\": 500000,\n",
      "  \"vae_hidden_size\": 750,\n",
      "  \"max_latent_action\": 2.0,\n",
      "  \"phi\": 0.0,\n",
      "  \"batch_size\": 100,\n",
      "  \"actor_lr\": 0.0001,\n",
      "  \"critic_lr\": 0.001,\n",
      "  \"tau\": 0.005,\n",
      "  \"node\": \"computer\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./results/Exp0001_Latent_bullet-walker2d-random-v0-0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if args.dataset is None:\n",
    "    args.dataset = args.env_name\n",
    "\n",
    "# Setup Logging\n",
    "file_name = f\"Exp{args.ExpID:04d}_{args.algo_name}_{args.dataset}-{args.seed}\"\n",
    "folder_name = os.path.join(args.log_dir, file_name)\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "print(folder_name)\n",
    "if os.path.exists(os.path.join(folder_name, 'variant.json')):\n",
    "    raise AssertionError\n",
    "variant = vars(args)\n",
    "variant.update(node=os.uname()[1])\n",
    "setup_logger(os.path.basename(folder_name), variant=variant, log_dir=folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57f860-2cf1-4e4f-86d8-318bf272b310",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7873784-fd84-46b6-98c1-422ab9646556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TimeLimit<OrderEnforcingNormalized: <OfflineWalker2dEnv instance>>>\n",
      "22\n",
      "6\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prince/anaconda3/envs/plas/lib/python3.7/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "# Setup Environment\n",
    "env = gym.make(args.env_name)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = float(env.action_space.high[0])\n",
    "\n",
    "# Set seeds\n",
    "env.seed(args.seed)\n",
    "env.action_space.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "# check\n",
    "print(env)\n",
    "print(state_dim)\n",
    "print(action_dim)\n",
    "print(max_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51e7189-441d-48c0-9768-3959b8b4750e",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58ec8495-e13e-40d3-916d-9e67d7446c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load datafile: 100%|██████████| 7/7 [00:00<00:00,  7.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "if args.env_name == args.dataset:\n",
    "    dataset = d4rl.qlearning_dataset(env)  # Load d4rl dataset\n",
    "else:\n",
    "    if args.dataset == 'hopper-medium-expert':\n",
    "        dataset1 = d4rl.qlearning_dataset(gym.make('hopper-medium-v0'))\n",
    "        dataset2 = d4rl.qlearning_dataset(gym.make('hopper-expert-v0'))\n",
    "        dataset = {key:np.concatenate([dataset1[key], dataset2[key]]) for key in dataset1.keys()}\n",
    "        print(\"Loaded data from hopper-medium-v0 and hopper-expert-v0\")\n",
    "    else:\n",
    "        dataset_file = os.path.dirname(os.path.abspath(__file__)) + '/dataset/'+args.dataset + '.pkl'\n",
    "        dataset = pickle.load(open(dataset_file,'rb'))\n",
    "        print(\"Loaded data from \"+dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "971bffe8-e8e5-477b-9ac2-3eebc6a5091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999999, 22)\n",
      "(999999, 6)\n",
      "(999999,)\n",
      "(999999,)\n"
     ]
    }
   ],
   "source": [
    "print(dataset['observations'].shape)\n",
    "print(dataset['actions'].shape)\n",
    "print(dataset['rewards'].shape)\n",
    "print(dataset['terminals'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87c17b-637c-4742-a99b-b70baea3a27e",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "162ce1bf-e4a4-40ed-b253-09677a6c1bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 6, 12, 1.0, 0.0001, 750)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim = action_dim * 2\n",
    "state_dim, action_dim, latent_dim, max_action, args.vae_lr, args.vae_hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f783b24-db0b-4d82-ba7c-cb60d57477b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define VAE\n",
    "vae_trainer = algos.VAEModule(state_dim, action_dim, latent_dim, max_action, vae_lr=args.vae_lr, hidden_size=args.vae_hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180a298-b849-4afa-97d6-4d571bca0767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 29 16:29:06 2022 Training VAE...\n",
      "Itr 50000 Training loss:0.2555\n",
      "Itr 100000 Training loss:0.2564\n",
      "Itr 150000 Training loss:0.243\n",
      "Itr 200000 Training loss:0.2431\n",
      "Itr 250000 Training loss:0.2377\n",
      "Itr 300000 Training loss:0.2338\n",
      "Itr 350000 Training loss:0.2492\n",
      "Itr 400000 Training loss:0.2445\n"
     ]
    }
   ],
   "source": [
    "# Train or Load VAE\n",
    "if args.vae_mode == 'train':\n",
    "    # Train VAE\n",
    "    print(time.ctime(), \"Training VAE...\")\n",
    "    logs = vae_trainer.train(dataset, folder_name, iterations=args.vae_itr)\n",
    "else:\n",
    "    # Select vae automatically\n",
    "    vae_dirname = os.path.dirname(os.path.abspath(__file__)) + '/models/vae_' + args.vae_mode\n",
    "    vae_filename = args.dataset + '-' + str(args.seed)\n",
    "    vae_trainer.load(vae_filename, vae_dirname)\n",
    "    print('Loaded VAE from:' + os.path.join(vae_dirname, vae_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad03fd65-440d-4b74-9d79-e2f8ec816731",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = utils.ReplayBuffer(state_dim, action_dim)\n",
    "replay_buffer.load(dataset)\n",
    "\n",
    "policy = None\n",
    "if args.algo_name == 'Latent':\n",
    "    policy = algos.Latent(vae_trainer.vae, state_dim, action_dim, latent_dim, max_action,**vars(args))\n",
    "elif args.algo_name == 'LatentPerturbation':\n",
    "    policy = algos.LatentPerturbation(vae_trainer.vae, state_dim, action_dim, latent_dim, max_action,**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c4f72-d2ac-435d-8eb0-989e44ebc806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs policy for X episodes and returns average reward\n",
    "# A fixed seed is used for the eval environment\n",
    "def eval_policy(policy, env, eval_episodes=30, random=False):\n",
    "    avg_reward = 0.\n",
    "    for _ in range(eval_episodes):\n",
    "        state, done = env.reset(), False\n",
    "        while not done:\n",
    "            if random:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = policy.select_action(np.array(state))\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            avg_reward += reward\n",
    "\n",
    "    avg_reward /= eval_episodes\n",
    "\n",
    "    info = {'AverageReturn': avg_reward}\n",
    "    print (\"---------------------------------------\")\n",
    "    print(f\"Evaluation over {eval_episodes} episodes: {avg_reward:.3f}\")\n",
    "    print (\"---------------------------------------\")\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438d764-3068-469d-ac4e-53ea103fee71",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "episode_num = 0\n",
    "done = True\n",
    "training_iters = 0\n",
    "evaluations = []\n",
    "best_perf = 0\n",
    "best_policy = None\n",
    "\n",
    "while training_iters < args.max_timesteps:\n",
    "    # Train\n",
    "    pol_vals = policy.train(replay_buffer, iterations=int(args.eval_freq), batch_size=args.batch_size)\n",
    "    training_iters += args.eval_freq\n",
    "    print(\"Training iterations: \" + str(training_iters))\n",
    "    logger.record_tabular('Training Epochs', int(training_iters // int(args.eval_freq)))  \n",
    "    \n",
    "    # Save BEST Model\n",
    "    if training_iters % args.save_freq == 0 and args.save_model:\n",
    "        \n",
    "        # evaluate policy\n",
    "        info = eval_policy(policy, env)       \n",
    "        \n",
    "        if info['AverageReturn'] > best_perf:\n",
    "            best_perf = info['AverageReturn']\n",
    "            best_policy = deepcopy(policy)\n",
    "            \n",
    "            policy.save('model_' + str(training_iters), folder_name)\n",
    "        \n",
    "        evaluations.append(info['AverageReturn'])  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9264ea7a-5fe3-47a7-9677-9f888e315120",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, training_iters, args.save_freq)\n",
    "y = evaluations\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e9bec-7651-436c-8d5d-01e31b0ea1fa",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e7dbcf-f5e1-44ad-91b1-dea8785b3439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import matplotlib.pyplot as plt    \n",
    "\n",
    "def _label_with_episode_number(frame, episode_num):\n",
    "    im = Image.fromarray(frame)\n",
    "\n",
    "    drawer = ImageDraw.Draw(im)\n",
    "\n",
    "    if np.mean(im) < 128:\n",
    "        text_color = (255,255,255)\n",
    "    else:\n",
    "        text_color = (0,0,0)\n",
    "    drawer.text((im.size[0]/20,im.size[1]/18), f'Episode: {episode_num+1}', fill=text_color)\n",
    "\n",
    "    return im\n",
    "\n",
    "\n",
    "def save_agent_gif(env, random=False, fname='agent.gif', n_iter = 5):\n",
    "    frames = []\n",
    "    for i in range(n_iter):\n",
    "        state = env.reset()        \n",
    "        for t in range(500):\n",
    "            \n",
    "            if random:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = best_policy.select_action(state)\n",
    "\n",
    "            frame = env.render(mode='rgb_array')\n",
    "            frames.append(_label_with_episode_number(frame, episode_num=i))\n",
    "\n",
    "            state, _, done, _ = env.step(action)\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "    env.close()\n",
    "    imageio.mimwrite(os.path.join(folder_name, fname), frames, fps=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8366ebd-cc29-45bf-b119-e9b6164b17cd",
   "metadata": {},
   "source": [
    "### Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660765df-d055-43de-9d7b-152a36fc3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eval\n",
    "evaluations = []\n",
    "info = eval_policy(best_policy, env, random=True)\n",
    "evaluations.append(info['AverageReturn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9ce31-09c3-42c3-8e75-a51d1e50c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('bullet-walker2d-medium-v0')\n",
    "save_agent_gif(env, random=True, fname='random.gif', n_iter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69a89b1-3143-4c7a-9a6c-f1b96816fc58",
   "metadata": {},
   "source": [
    "### Exactly the same environment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab5f662-ec96-431f-866d-ba9dc167eb42",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Eval\n",
    "evaluations = []\n",
    "info = eval_policy(best_policy, env)\n",
    "evaluations.append(info['AverageReturn'])\n",
    "np.save(os.path.join(folder_name, 'eval'), evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea40e82-f31c-432d-a9d2-5762a1167f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('bullet-walker2d-medium-v0')\n",
    "save_agent_gif(env, fname='agent1.gif', n_iter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc922206-af1b-43b0-a398-a3d0e7c8163b",
   "metadata": {},
   "source": [
    "### Tweaked environment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b71e51-a401-4bbe-a083-a1978d1aa7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change environment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863cb4ca-8f88-416c-99aa-2862569465bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
